Task 1 : Medical NLP Summarization Q1: How to handle ambiguous or missing medical data?Approaches:1. Contextual Inference: Use surrounding context to infer missing information2. Default Values: Provide standard defaults for common fields3. Confidence Scores: Indicate certainty levels for extractions4. Multi-model Ensemble: Combine multiple models for robust extraction5. Human-in-the-loop: Flag uncertain cases for manual review6. Ontology Mapping: Use medical ontologies (SNOMED, ICD-10) for standardizationQ2: Which pre-trained NLP models for medical summarization?Recommended Models:* ScispaCy (en_core_med7_lg): Medical NER* Bio_ClinicalBERT: Clinical text understanding* BioBERT: Biomedical literature* ClinicalBERT: MIMIC-III trained* BART/T5: Fine-tuned on medical summaries* BioGPT: Medical text generationTask 2 : Sentiment & Intent Analysis Q1: How to fine-tune BERT for medical sentiment?Steps:1. Load Bio_ClinicalBERT base model2. Add classification head (3 classes: Anxious, Neutral, Reassured)3. Prepare training data from medical conversations4. Use small learning rate (2e-5) and warmup5. Train with medical-specific augmentation6. Validate on held-out clinical data Q2: Which datasets for healthcare sentiment model?Datasets:* MIMIC-III: ICU clinical notes* i2b2 Challenges: Various medical NLP tasks* Medical Transcripts: Annotated conversations* PubMed: Biomedical literature* Mental Health Forums: Patient sentiment data